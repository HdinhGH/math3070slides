\documentclass[t,handout]{beamer}
\usepackage{verbatim}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{hyperref}
\usetikzlibrary{positioning,fit}
%\usepackage{enumitem}
\usetheme{Warsaw}
\setbeamertemplate{navigation symbols}{}
\newcommand{\blue}[1]{{\color{blue} #1}}
\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\grn}[1]{{\color{green} #1}}
\newcommand{\bluRed}[2]{{\color{blue} #1}{\color{red} #2}}
\newcommand{\qtns}[0]{\begin{center} Questions? \end{center}}
\newcommand{\nl}[1]{\vspace{#1 em}}
\newcommand{\cntrImg}[2]{\begin{center}\includegraphics[scale=#2]{#1}\end{center}}
\newcommand{\defn}[1]{{\bf #1}}
\let\emptyset\varnothing
\newcommand{\SampS}[0]{$\mathcal{S}$}

\title{Math 3070, Applied Statistics}

\setlength{\abovedisplayskip}{0pt}
\setlength{\belowdisplayskip}{0pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}

\begin{document}
\begin{frame}[c]
    \begin{beamercolorbox}[rounded=true,wd=\textwidth,center]{title}
        \usebeamerfont{title}\inserttitle
    \end{beamercolorbox}
    \begin{center}
        Section 1\\
        \nl{0.5}
        November 8, 2019
    \end{center}
\end{frame}
\begin{frame}[c]{Lecture Outline, 11/8}
    Section 8.1
    \begin{itemize}
        \item Hypothesis Testing
    \end{itemize}
\end{frame}

\begin{frame}{Statistical Hypotheses}
    A \emph{hypothesis} is an assertion about a distribution or its parameters. \pause For example,
    \begin{itemize}
    \item Given a coin, one hypothesis is that each toss has probability $p=.5$ of coming up heads. \pause Another hypothesis would be that $p\neq .5$.
    \pause \item Given a certain type of candy bar, labeled as having a mass of 60 grams, one hypothesis is that the mean mass is as labeled, $\mu=60$. \pause Another hypothesis would be that the mean mass is smaller than labeled: $\mu<60$.
    \end{itemize}
    \end{frame}
    
    \begin{frame}{Hypothesis Testing}
    In a hypothesis-testing problem, we consider two contradictory hypotheses $H_0$ and $H_a$.
    \begin{itemize}
    \pause \item $H_0$, the \emph{null hypothesis}, is the hypothesis which we initially presume to be true.
    \pause \item The other hypothesis $H_a$ is called the \emph{alternative hypothesis}.
    \pause \item The hypothesis $H_0$ is rejected only if the sample evidence strongly contradicts it. Otherwise we continue to believe that $H_0$ is plausible.
    \pause \item The two possible outcomes of the analysis are that we \emph{reject} the null hypothesis $H_0$, or we \emph{do not reject} the null hypothesis.
    \item $H_0$ and $H_a$ should be disjoint.
    \end{itemize}
    
    \end{frame}

    \begin{frame}{Example}
        Suppose someone claims that a coin is unfair, that it gives heads more than half the time. \pause The null hypothesis would be $H_0: p=.5$, that the coin is fair. \pause The alternative hypothesis is $H_a: p>.5$.
        
        \vspace{.2cm}
        \pause To test the claim, we could toss the coin for several trials and reject $H_0$ if the number of heads we obtain is larger than a certain amount. 
        
        \vspace{.2cm}
        \pause For example, one procedure would be to toss the coin 10 times and reject the null hypothesis if we obtain 8 heads or more.
        \end{frame}

        \begin{frame}{Test Procedures}
            \begin{itemize}
            \item In general, to test a statistical hypothesis, we select a \emph{test statistic} that can be calculated from a random sample. 
            
            \pause \item Out of the possible values of the test statistic, we select a subset of values which are unlikely to occur if the null hypothesis $H_0$ is true; this subset is called the \emph{rejection region}. 
            
            \pause\item We then obtain data from a random sample, calculate the test statistic for the data, and reject $H_0$ if the test statistic is in the rejection region.
            \end{itemize}
            
            \pause For the example of testing for an unfair coin, the test statistic was the number of heads $X$ out of 10 tosses, and the rejection region was $\{8,9,10\}$.
            \end{frame}
            
            \begin{frame}{Errors in Hypothesis Testing}
            For essentially any test procedure, there is a chance that the test will give a misleading conclusion:
            \begin{itemize}
            \pause\item When the null hypothesis $H_0$ is true but is rejected, this is called a \emph{Type I error}.
            \pause\item When the null hypothesis $H_0$ is false but is not rejected, this is called a \emph{Type II error}.
            \end{itemize}
            \pause We cannot eliminate the possibility of these errors. However, we can quantify their probability of occuring:
            \begin{itemize}
            \pause\item The probability of a Type I error is denoted by $\alpha$.
            \pause\item The probability of a Type II error is denoted by $\beta$.
            \end{itemize}
            \pause Typically, the choice of rejection region involves a tradeoff between the two types of errors. \pause But by using larger samples, both error probabilities may be reduced.
            \end{frame}
            \begin{frame}{Example}
\begin{block}{}
Suppose we test a coin by tossing it 10 times and rejecting it if we get 8 or more heads. If in reality the coin is fair, what is the probability $\alpha$ of a Type I error? If the coin is unfair with probability $p=.75$ of being heads, what is the probability $\beta$ of a Type II error?
\end{block}
\pause To find the Type I error, we assume $p=.5$ and calculate the probability that the number of heads $X$ is at least 8:
\pause $$\alpha = P(X \geq 8) = \sum_{x=8}^{10} \binom{10} x (.5)^x(1-.5)^{10-x}= .055$$
\pause To find the Type II error in the case $p=.75$, we calculate the probability that the number of heads $X$ is less than 8:
\pause $$\beta = P(X < 8) = \sum_{x=0}^7 \binom{10} x (.75)^x(.25)^{10-x} = .474$$
\end{frame}

\begin{frame}{Example}
\begin{block}{}
In the previous example, how do the error probabilities change if we instead reject the coin if we get 7 or more heads out of 10?
\end{block}
\pause To find the Type I error, we assume $p=.5$ and calculate the probability that the number of heads $X$ is at least 7:
\pause $$\alpha = P(X \geq 7) = \sum_{x=7}^{10} \binom{10} x (.5)^x(1-.5)^{10-x}= .171$$
\pause To find the Type II error in the case $p=.75$, we calculate the probability that the number of heads $X$ is less than 7:
\pause $$\beta = P(X < 7) = \sum_{x=0}^6 \binom{10} x (.75)^x(.25)^{10-x} = .224$$
By enlarging the rejection region, we increased $\alpha$ but decreased $\beta$.
\end{frame}

\begin{frame}{Example}
    \begin{block}{}
    Suppose we test a coin by tossing it 10 times and rejecting it if we get 8 or more heads. If in reality the coin is fair, what is the probability $\alpha$ of a Type I error? If the coin is unfair with probability $p=.75$ of being heads, what is the probability $\beta$ of a Type II error?
    \end{block}
    \pause To find the Type I error, we assume $p=.5$ and calculate the probability that the number of heads $X$ is at least 8:
    \pause $$\alpha = P(X \geq 8) = \sum_{x=8}^{10} \binom{10} x (.5)^x(1-.5)^{10-x}= .055$$
    \pause To find the Type II error in the case $p=.75$, we calculate the probability that the number of heads $X$ is less than 8:
    \pause $$\beta = P(X < 8) = \sum_{x=0}^7 \binom{10} x (.75)^x(.25)^{10-x} = .474$$
    \end{frame}
    
    \begin{frame}{Example}
    \begin{block}{}
    In the previous example, how do the error probabilities change if we instead reject the coin if we get 7 or more heads out of 10?
    \end{block}
    \pause To find the Type I error, we assume $p=.5$ and calculate the probability that the number of heads $X$ is at least 7:
    \pause $$\alpha = P(X \geq 7) = \sum_{x=7}^{10} \binom{10} x (.5)^x(1-.5)^{10-x}= .171$$
    \pause To find the Type II error in the case $p=.75$, we calculate the probability that the number of heads $X$ is less than 7:
    \pause $$\beta = P(X < 7) = \sum_{x=0}^6 \binom{10} x (.75)^x(.25)^{10-x} = .224$$
    By enlarging the rejection region, we increased $\alpha$ but decreased $\beta$.
    \end{frame}

    \begin{frame}{Problem}
        \begin{block}{}
        A type of candy bar is labeled 60 grams. We decide to test the label's accuracy using a random sample $X_1,\dots,X_5$ by rejecting the null hypothesis $H_0: \mu=60$ if $\overline X<59$. If the actual mean mass is $\mu=58.5$, and $\sigma=0.8$, what is the Type II error probability $\beta$?
        \end{block}
        
        \pause In this case, $Z=\frac{\overline X-\mu}{\sigma/\sqrt{n}}=\frac{\overline X-58.5}{0.8/\sqrt{5}}$ is a standard normal random variable, \pause so
        \begin{align*}
        \beta &= P(\overline X\geq 59) \\
        &= P\left(\frac{\overline X-58.5}{0.8/\sqrt5} \geq \frac{59-58.5}{0.8/\sqrt5}\right)\\
        &= P(Z \geq 1.40) \\
        &= .0808
        \end{align*}
        
        \end{frame}

    \begin{frame}{Significance Level}
        As we have seen, for a fixed sample size, selecting a rejection region for a test involves a tradeoff between the Type I error probabilities $\alpha$ and the Type II error probability $\beta$. 
        
        \vspace{.2cm}
        \pause A common practice is to design the test to achieve a specified small value of $\alpha$, such as $\alpha=.1, .05$, or .01. The choice for $\alpha$ is called the \emph{significance level}.
        \end{frame}

        \begin{frame}{P-Values}
            There is a major drawback of the hypothesis-testing procedures considered so far:
            The tests each only have two outcomes -- reject or do not reject -- even if the test statistic is near the border of the rejection region. 
            
            \vspace{.2cm}
            \pause One way to remedy this is to report the so-called P-value:
            
            \begin{block}{}
            The \emph{P-value} is the smallest significance level $\alpha$ for which the test would reject the null hypothesis.
            \end{block}
            
            \pause For example, in the candy bar example, at the $\alpha=.01$ we failed to reject the null hypothesis; however, if we had used a less strict significance level, $\alpha=.05$, then the test would have rejected. \pause The P-value would provide a more nuanced summary of the test result by indicating precisely at what significance level the test changes from rejecting to failing to reject.
            \end{frame}
            
            \begin{frame}{P-Values}
            
            Loosely speaking, another way to describe the P-value is as follows:
            \begin{block}{}
            The \emph{P-value} is the probability, calculated assuming that the null hypothesis is
            true, of obtaining a value of the test statistic at least as extreme as the value actually observed.
            \end{block}
            \pause
            Here are some key points:
            \begin{itemize}
            \item The P-value is a probability.
            \pause \item This probability is calculated assuming that the null hypothesis is true.
            \pause \item Beware: The P-value is not the probability that $H_0$ is true.
            \pause \item The interpretation of ``as extreme as" depends on the alternative hypothesis:
            \begin{itemize}
            \item Consider hypotheses $H_0: \mu = 0$ and $H_A: \mu > 0$. With a test statistic of $\overline{X} = 0.5$. The p-value is $P(\overline{X}>0.5|\mu=0)$. 'As extreme as' is interperted as 'as large as'. $\mu=0$ can be implemented by conditioning.
             \end{itemize}
            \end{itemize}
            \end{frame}

            \begin{frame}{Hypothesis Testing Framework}
            
                If the p-value is smaller than the significance level ($p<\alpha$) , we reject $H_0$. The data is too unlikely, as determined by $\alpha$, given our assumption $H_0$.
                \\
                \nl{0.5}
                If the p-value is larger than the significance level ($p\geq \alpha$) , we fail to reject $H_0$. The data is plausible, as determined by $\alpha$, given our assumption $H_0$.
                \\
                \nl{2}
                Note: smaller $\alpha$ is more likely reject to a p-value so we expect a larger rejection region and hypotheses will be defined on more complicated sets. For example:
                \begin{itemize}
                    \item $H_0: \mu \geq 2$ and $H_A: \mu <2$
                     \item $H_0: \mu = 2$ and $H_A: \mu \neq 2$
                \end{itemize}
            \end{frame}

\end{document}